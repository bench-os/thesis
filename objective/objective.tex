\section{Implementing a benchmarking framework}

The first question one can ask is "What does benchmarking an embedded system means?".
A benchmark measures the performances of a defined system, in our case, an embedded system.
Those performances can be measured in terms of latency, memory usage or even power consumption.
But we can also see benchmarks that include reliability, interoperability or stability measurements.

As part of our work, we want to answer two questions.

\begin{itemize}
  \item Is it possible to implement a benchmarking framework able to measure precise performance metrics, such as the context switching time, without using an oscilloscope?
  \item Is it possible to implement a benchmarking framework aware of the RTOS that could give useful metrics such as the memory usage, the power consumption or the CPU utilization? % TODO Reformulate this question
\end{itemize}

\subsection{Motivations}

In the RTOS world, benchmarks already exist and some of them are even com\-mer\-cia\-lized. \cite{mibench, parmibench, performance-benchmarking}
However, those benchmarks are just workloads.
They use a defined set of routines that is used to measure the performances of a RTOS.
This does not reflect the performances of a real-world application.
A benchmark must be a tool that a developer can use to make a fair comparison of two systems.

Developers find themselves using other tools to assess the performances of their applications.
Let's take for example, the case of a developer who wants to measure the latency of its application.
A benchmark will only provide a latency measurement based on predefined tasks and within a controlled environment.
If our developer wants to measure the real latency of its application, he will need to use an oscilloscope and take the time to do the measurements.

However, these devices are expensive and some developers cannot afford them.
Furthermore, working with external devices takes time and can dramatically slow down the development process.

For those reasons, we wanted to build a benchmarking framework that the developer could run on any RTOS with any application.

Ideally, the use case for any developer using our benchmarking framework would be the following.
This scenario is hypothetical and does not represent the state of our work.
The developer implements an application with multiple tasks on a specific device.
The developer wants to measure the performance of its application and, to do so, set a flag in the Makefile of its application to turn on the benchmarking framework.
The developer flashes its application on the device and the framework outputs continuous performance measurement of the application.
With this framework, the developer can optimize its application or change the device and check if the measurements are improved.

\subsection{Criteria}

Ideally, this framework would respect the following criteria in order to be useful for a real-world application.

\paragraph{Widely distributed}
By making our framework accessible on a large variety of RTOS, we allow developers not to limit themselves to a specific set of RTOS.
With this framework, they would be able to assess the performance of their applications regardless of the platform.

\paragraph{Providing a large variety of metrics}
Our framework should be able to provide performance measurements on interrupt latency, context switching time.
Those metrics are important for a real-time context applications.
Also, using constrained devices requires to monitor the memory usage and the energy consumption of the applications.
Our framework should be able to provide those metrics as well.

\paragraph{Hidden for the developer}
The developer should not need to worry about integrating our framework in its application.
Using it or not, our framework should not change the source code of the application and allow the developer to directly deploy it in a production environment.

\paragraph{Easy to use and to configure}
Using an oscilloscope or any external device to benchmark an embedded application takes time and effort for the developer.
Our framework should be able to improve the benchmarking process by being easy to use and easy to configure.

\subsection{Approaches}

In order to develop this framework, we explored three different approaches.
We introduced them here so that the reader has already in mind our three experiments but each one of them is described later in the chapter \ref{chap:experiment}.

\paragraph{Integrating the framework in the kernel of the RTOS}
Our first approach was to integrate the framework in the heart of the RTOS.
By focusing our implementation in the kernel space, we would be able to retrieve performance measurements without altering the user space and the application.
This approach is detailed in the section \ref{sec:kernel}.

\paragraph{Implementing the framework as an extension of the RTOS}
The majority of RTOS allow users to develop their own extension without altering the kernel source code.
We chose to investigate this opportunity with our second approach.
The framework would be an extension of RTOS.
This implementation is explained in the section \ref{sec:extension}.

\paragraph{Using external devices}
Finally, our last approach was to use external devices such as a computer or an external board to benchmark our real-world application.
This last idea is described in the section \ref{sec:external}.
